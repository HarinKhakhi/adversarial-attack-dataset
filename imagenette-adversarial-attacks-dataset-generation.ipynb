{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install adversarial-robustness-toolbox > /dev/null","metadata":{"id":"B5RzaWaJfm9P","execution":{"iopub.status.busy":"2022-12-31T07:05:26.670113Z","iopub.execute_input":"2022-12-31T07:05:26.670625Z","iopub.status.idle":"2022-12-31T07:05:38.898001Z","shell.execute_reply.started":"2022-12-31T07:05:26.670523Z","shell.execute_reply":"2022-12-31T07:05:38.896873Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import tarfile\nfrom urllib.request import urlopen\nfrom os import makedirs, listdir\nfrom os.path import join, exists\nimport json\nimport time\n\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport csv\n# from tqdm import tqdm\nfrom tqdm.notebook import tqdm\n\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.applications import inception_v3\nfrom art.estimators.classification import TensorFlowV2Classifier\n\nfrom art.attacks.evasion import FastGradientMethod\nfrom art.attacks.evasion import ProjectedGradientDescent\nfrom art.attacks.evasion import BasicIterativeMethod\nfrom art.attacks.evasion import CarliniL2Method\nfrom art.attacks.evasion import CarliniLInfMethod","metadata":{"id":"p3GKRANWQFD5","execution":{"iopub.status.busy":"2022-12-31T07:39:17.938106Z","iopub.execute_input":"2022-12-31T07:39:17.939119Z","iopub.status.idle":"2022-12-31T07:39:17.946716Z","shell.execute_reply.started":"2022-12-31T07:39:17.939080Z","shell.execute_reply":"2022-12-31T07:39:17.945560Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"dataset_label = \"Imagenette\"\ninput_dataset_link = \"https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\"\nlabels_link = \"https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\"\nimagenette_directory = \"./imagenette2/train\"\n\ninput_dataset_content = urlopen(input_dataset_link)\ninput_dataset_tar = tarfile.open(fileobj=input_dataset_content, mode=\"r|gz\")\ninput_dataset_tar.extractall()\n\nlabels_content = urlopen(labels_link)\nlabels = json.loads(labels_content.read()) \n\nlabels = {int(index): value for index,value in labels.items()}\nclass_to_index = {value[0]: int(index) for index,value in labels.items()}","metadata":{"id":"AEXR6wFrd0WP","execution":{"iopub.status.busy":"2022-12-31T07:05:47.053134Z","iopub.execute_input":"2022-12-31T07:05:47.053553Z","iopub.status.idle":"2022-12-31T07:06:19.287835Z","shell.execute_reply.started":"2022-12-31T07:05:47.053516Z","shell.execute_reply":"2022-12-31T07:06:19.286399Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"org_dataset_directory = f\"./{dataset_label}/Original\"\nadv_dataset_directory = f\"./{dataset_label}/Adversarial\"\nmetadata_file = f\"./{dataset_label}/metadata.csv\"\nmetadata_fields = [\n  \"org_image\", \"adv_image\", \"adv_npz\", \n  \"attack_type\", \"eps\", \"eps_step\", \"max_iter\", \"attack_time\",\n  'org_label', 'adv_label',\n  \"status\"\n]\nfor top_k in range(5):\n    metadata_fields.append(f'org_top{top_k+1}_index')\n    metadata_fields.append(f'org_top{top_k+1}_prob')\n    metadata_fields.append(f'adv_top{top_k+1}_index')\n    metadata_fields.append(f'adv_top{top_k+1}_prob')","metadata":{"execution":{"iopub.status.busy":"2022-12-31T07:06:19.295945Z","iopub.execute_input":"2022-12-31T07:06:19.299000Z","iopub.status.idle":"2022-12-31T07:06:19.310985Z","shell.execute_reply.started":"2022-12-31T07:06:19.298949Z","shell.execute_reply":"2022-12-31T07:06:19.309737Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"image_size = (300, 300, 3)\npixel_range = 2 # range of processed image will be -1 to 1","metadata":{"id":"ktjBBmltXPOm","execution":{"iopub.status.busy":"2022-12-31T07:07:38.078692Z","iopub.execute_input":"2022-12-31T07:07:38.079105Z","iopub.status.idle":"2022-12-31T07:07:38.089609Z","shell.execute_reply.started":"2022-12-31T07:07:38.079071Z","shell.execute_reply":"2022-12-31T07:07:38.088627Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"eps(02)_eps_step(01)\n","output_type":"stream"}]},{"cell_type":"code","source":"inception_model = inception_v3.InceptionV3(input_tensor=Input(shape=image_size),\n                                 include_top=True, \n                                 weights='imagenet', \n                                 classifier_activation='softmax')\n\nloss = CategoricalCrossentropy(from_logits=False)\n\nclassifier = TensorFlowV2Classifier(model=inception_model,\n                                    nb_classes=1000,\n                                    loss_object=loss,\n                                    input_shape=image_size,\n                                    clip_values=(-1,1))","metadata":{"id":"LYjVM3iPSj18","colab":{"base_uri":"https://localhost:8080/"},"outputId":"db0d0008-a949-4488-ca8c-ee4c306c5764","execution":{"iopub.status.busy":"2022-12-31T07:07:38.101001Z","iopub.execute_input":"2022-12-31T07:07:38.101625Z","iopub.status.idle":"2022-12-31T07:07:45.975662Z","shell.execute_reply.started":"2022-12-31T07:07:38.101592Z","shell.execute_reply":"2022-12-31T07:07:45.974694Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"2022-12-31 07:07:38.235127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-31 07:07:38.236687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-31 07:07:38.237671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-31 07:07:38.238798: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-12-31 07:07:38.239106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-31 07:07:38.240074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-31 07:07:38.241029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-31 07:07:43.273029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-31 07:07:43.274070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-31 07:07:43.274848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-31 07:07:43.275455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15043 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n96116736/96112376 [==============================] - 1s 0us/step\n96124928/96112376 [==============================] - 1s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"adv_dataset_images = join(adv_dataset_directory,attack_type,'Images')\nadv_dataset_npz = join(adv_dataset_directory,attack_type,'NPZ')\nif not exists(adv_dataset_images): makedirs(adv_dataset_images)\nif not exists(adv_dataset_npz): makedirs(adv_dataset_npz)\n\nif not exists(metadata_file):\n    with open(metadata_file, 'w') as metadata_csv:\n        metadata_writer = csv.writer(metadata_csv)\n        metadata_writer.writerow(metadata_fields)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T07:07:45.986131Z","iopub.execute_input":"2022-12-31T07:07:45.986493Z","iopub.status.idle":"2022-12-31T07:07:45.995630Z","shell.execute_reply.started":"2022-12-31T07:07:45.986459Z","shell.execute_reply":"2022-12-31T07:07:45.994689Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def preprocess_input(image):\n    return inception_v3.preprocess_input(image)\n\ndef inverse_preprocess(image):\n    image = np.copy(image)\n    image += 1.0\n    image *= 127.5\n    image = image.astype(np.uint8)\n    return image\n\ndef predict(X, name=False):\n    if len(X.shape) == 3:\n        prediction = np.argmax(classifier.predict(\n                        np.expand_dims(X, axis=0)\n                    ), axis=1)\n\n        if name: return labels[prediction[0]][0]\n        else: return prediction[0]\n    else:\n        predictions = np.argmax(classifier.predict(X), axis=1)\n        if name: return map(lambda prediction: labels[prediction][0], predictions)\n        else: return predictions\n\ndef predict_top5(image):\n    y_pred = classifier.predict(np.expand_dims(image, axis=0))[0]\n    top5_inds = np.argsort(y_pred)[-5:][::-1]\n    top5_probs = y_pred[top5_inds] \n    return [{'index':ind, 'prob':prob} for ind,prob in zip(top5_inds, top5_probs)]\n    \ndef is_generated(adv_image_file):\n    metadata = pd.read_csv(metadata_file)\n    rows = metadata[metadata['adv_image'] == adv_image_file]\n    return len(rows) > 0\n\ndef write_metadata(row_dict):\n    with open(metadata_file, \"a\") as metadata_csv:\n        metadata_writer = csv.DictWriter(metadata_csv, fieldnames=metadata_fields)\n        metadata_writer.writerow(row_dict)\n        metadata_csv.close()","metadata":{"id":"CeXqg9VTkM3f","execution":{"iopub.status.busy":"2022-12-31T07:07:45.998331Z","iopub.execute_input":"2022-12-31T07:07:45.998669Z","iopub.status.idle":"2022-12-31T07:07:46.010494Z","shell.execute_reply.started":"2022-12-31T07:07:45.998636Z","shell.execute_reply":"2022-12-31T07:07:46.009475Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"attack_params = {\n    'eps': (1/100) * pixel_range,\n    'eps_step': 0.01,\n    'max_iter': 10\n}\nattack_params_str = '_'.join([f\"{param_name}({str(param_val).split('.')[-1]})\" for param_name, param_val in attack_params.items()])\n\nattack = FastGradientMethod(estimator=classifier, **attack_params)\n# attack = ProjectedGradientDescent(estimator=classifier, **attack_params, verbose=False)\n# attack = CarliniL2Method(classifier=classifier,  **attack_params, verbose=False)\n# attack = CarliniLInfMethod(classifier=classifier, **attack_params, verbose=False)\nattack_type = attack.__class__.__name__","metadata":{"execution":{"iopub.status.busy":"2022-12-31T07:19:10.565790Z","iopub.execute_input":"2022-12-31T07:19:10.566575Z","iopub.status.idle":"2022-12-31T07:19:10.573157Z","shell.execute_reply.started":"2022-12-31T07:19:10.566536Z","shell.execute_reply":"2022-12-31T07:19:10.571860Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# For debug purpose\nreconstructable = 0\nattack_done = 0\n\n# Generating Original Dataset\nclasses_dir = sorted(listdir(imagenette_directory))\nfor c_index, class_name in enumerate(tqdm(classes_dir, desc='Class', position=0)):\n\n    image_files = sorted(listdir(join(imagenette_directory, class_name)))\n    inner_tqdm = tqdm(image_files, position=1, leave=False)\n    for i_index, image_file in enumerate(inner_tqdm):        \n        inner_tqdm.set_description(f'Attacks: {attack_done} Reconstructable: {reconstructable}')\n        \n        # Creating all filenames\n        image_file_without_ext = image_file.split(\".\")[0]\n        org_image_file = join(imagenette_directory, class_name, image_file)\n        adv_image_file = join(adv_dataset_images, f'adv_{attack_type}_{attack_params_str}_{image_file_without_ext}.png')\n        adv_npz_file = join(adv_dataset_npz, f'adv_{attack_type}_{attack_params_str}_{image_file_without_ext}.npz')\n        \n        # Initializing Metadata \n        metadata = {}\n        metadata['org_image'] = org_image_file\n        metadata['org_label'] = class_name\n    \n        image = Image.open(org_image_file)\n    \n        # Filtering out images which are grayscaled\n        if image.getbands() == ('L',):\n            metadata['status'] = 'GRAYSCALED'\n            write_metadata(metadata)\n            continue\n    \n        # Rescaling images to make all image sizes same\n        org_image = np.asarray(image.resize((image_size[0], image_size[1])))\n        org_image_processed = preprocess_input(org_image)\n        \n        # Saving top 5 values to metadata\n        org_top5 = predict_top5(org_image_processed)\n        for topk, topk_item in enumerate(org_top5):\n            metadata[f'org_top{topk+1}_index'] = topk_item['index']\n            metadata[f'org_top{topk+1}_prob'] = topk_item['prob']\n        \n        # Filtering out images which are not correctly classified\n        y_pred = predict(org_image_processed, name=True)\n        if y_pred != class_name: \n            metadata['status'] = 'NOT_CORRECTLY_CLASSIFIED'\n            write_metadata(metadata)\n            continue\n        \n        # Saving attack params to metadata\n        metadata['attack_type'] = attack_type\n        if 'eps' in attack.attack_params: metadata['eps'] = attack_params['eps']\n        if 'eps_step' in attack.attack_params: metadata['eps_step'] = attack_params['eps_step']\n        if 'max_iter' in attack.attack_params: metadata['max_iter'] = attack_params['max_iter']\n        \n        # Generating adversarial version\n        start = time.perf_counter()\n        adv_image_processed = attack.generate(x=np.expand_dims(org_image_processed, axis=0))[0]\n        end = time.perf_counter()\n\n        # Filtering out images which are not successfully attacked\n        y_adv = predict(adv_image_processed, name=True)\n        if y_adv == class_name:\n            metadata['status'] = 'ATTACK_FAILED'\n            write_metadata(metadata)\n            continue\n    \n        # Saving NPZ file\n        attack_done += 1\n        np.savez_compressed(adv_npz_file, image=adv_image_processed)\n        metadata['adv_npz'] = adv_npz_file\n            \n        # Saving Attack result to metadata\n        metadata['adv_label'] = y_adv\n        metadata['attack_time'] = round(end-start, 2)\n        adv_top5 = predict_top5(adv_image_processed)\n        for topk, topk_item in enumerate(adv_top5):\n            metadata[f'adv_top{topk+1}_index'] = topk_item['index']\n            metadata[f'adv_top{topk+1}_prob'] = topk_item['prob']\n        \n        # Checking if the attack image generated can be converted to pixelized image\n        adv_image = inverse_preprocess(adv_image_processed)\n        adv_image_reconstructed = preprocess_input(adv_image)\n        \n        # Filtering out non-reconstrctable images\n        y_adv_reconstructed = predict(adv_image_reconstructed, name=True)\n        if y_adv != y_adv_reconstructed: \n            metadata['status'] = 'CAN_NOT_BE_RECONSTRUCTED'\n            write_metadata(metadata)\n            continue\n\n        # Saving image\n        reconstructable += 1\n        Image.fromarray(adv_image).save(adv_image_file)\n        metadata['adv_image'] = adv_image_file\n\n        # Writing metadata to file\n        metadata['status'] = 'SUCCESSFULL'\n        write_metadata(metadata)","metadata":{"id":"kfr8LppEVf6F","colab":{"base_uri":"https://localhost:8080/","height":709},"outputId":"7f9a96ba-1589-445f-d9b7-ac92ba828fd2","execution":{"iopub.status.busy":"2022-12-31T07:55:39.253162Z","iopub.execute_input":"2022-12-31T07:55:39.253564Z","iopub.status.idle":"2022-12-31T07:55:45.988029Z","shell.execute_reply.started":"2022-12-31T07:55:39.253530Z","shell.execute_reply":"2022-12-31T07:55:45.986638Z"},"trusted":true},"execution_count":68,"outputs":[{"output_type":"display_data","data":{"text/plain":"Class:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25f1f0fdc711495a85679831223ef14e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/963 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3270d58c5d3f461f9e80bb008b927ca7"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/4013281276.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Generating adversarial version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0madv_image_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morg_image_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \"\"\"\n\u001b[1;32m    199\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating adversarial samples.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_tensorflow_v2.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m                     \u001b[0;31m# first iteration: use the adversarial examples as they are the only ones we have now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                     adv_x[batch_index_1:batch_index_2] = self._generate_batch(\n\u001b[0;32m--> 220\u001b[0;31m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_eps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_eps_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     )\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_tensorflow_v2.py\u001b[0m in \u001b[0;36m_generate_batch\u001b[0;34m(self, x, targets, mask, eps, eps_step)\u001b[0m\n\u001b[1;32m    280\u001b[0m                 \u001b[0meps_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_random_init\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi_max_iter\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m             )\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_tensorflow_v2.py\u001b[0m in \u001b[0;36m_compute_tf\u001b[0;34m(self, x, x_init, y, mask, eps, eps_step, momentum, random_init)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# Get perturbation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mperturbation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_perturbation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;31m# Apply perturbation and clip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_tensorflow_v2.py\u001b[0m in \u001b[0;36m_compute_perturbation\u001b[0;34m(self, x, y, mask, decay, momentum)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;31m# Get gradient wrt loss; invert it if attack is targeted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         grad: tf.Tensor = self.estimator.loss_gradient(x, y) * tf.constant(\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargeted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mART_NUMPY_DTYPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/art/estimators/classification/tensorflow.py\u001b[0m in \u001b[0;36mloss_gradient\u001b[0;34m(self, x, y, training_mode, **kwargs)\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    598\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m           data_format=data_format)\n\u001b[0m\u001b[1;32m    601\u001b[0m   ]\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_filter\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m         data_format, \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"metadata =pd.read_csv(metadata_file)\n# metadata[metadata.adv_image.notna()][[\"org_image\",\"adv_image\"]]\n# list(metadata[metadata.org_image == metadata.iloc[2]['org_image']]['adv_image'])","metadata":{"execution":{"iopub.status.busy":"2022-12-31T07:28:43.128167Z","iopub.execute_input":"2022-12-31T07:28:43.129160Z","iopub.status.idle":"2022-12-31T07:28:43.141118Z","shell.execute_reply.started":"2022-12-31T07:28:43.129123Z","shell.execute_reply":"2022-12-31T07:28:43.140145Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}